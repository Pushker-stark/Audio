{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conceptor.util' from '/Users/xuhe/Documents/GSoC/speaker-recognition/src/Preprocessing/conceptor/util.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import conceptor.util as util\n",
    "import conceptor.reservoir as reservoir\n",
    "import conceptor.logic as logic\n",
    "import conceptor.recognition as recog\n",
    "from imp import reload\n",
    "reload(reservoir)\n",
    "reload(recog)\n",
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the Japanese vouwels data to Python\n",
    "\n",
    "train = np.loadtxt('./ae.train')\n",
    "test = np.loadtxt('./ae.test')\n",
    "  \n",
    "num_test=370\n",
    "num_train = 270\n",
    "\n",
    "train_inputs = []\n",
    "read_index = 0 \n",
    "for c in range(num_train):    \n",
    "    l = 0\n",
    "    while(train[read_index, 0] != 1.0):\n",
    "        l += 1\n",
    "        read_index += 1\n",
    "    train_inputs.append(train[read_index - l : read_index, :].T)\n",
    "    read_index += 1\n",
    "    \n",
    "    \n",
    "test_inputs = []\n",
    "read_index = 0\n",
    "for c in range(num_test):\n",
    "    l = 0\n",
    "    while(test[read_index, 0]!=1.0):\n",
    "        l += 1\n",
    "        read_index += 1\n",
    "    test_inputs.append(test[read_index - l : read_index, :].T)\n",
    "    read_index += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_inputs, shifts, scales = util.normalize_data(train_inputs)\n",
    "test_inputs = util.transform_data(test_inputs, shifts, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "virtualLength = 4\n",
    "polyOrder = 3\n",
    "num_train = len(train_inputs)\n",
    "\n",
    "for i in range(num_train):\n",
    "    p = train_inputs[i]\n",
    "    pNew = np.zeros((12, virtualLength))\n",
    "    l = p.shape[1]\n",
    "    fitpts = np.asarray(range(l))\n",
    "    intPts = np.linspace(0, l-1, num = 4)\n",
    "    for s in range(12):\n",
    "        polyCoeffs = np.polyfit(fitpts, p[s, :], polyOrder)\n",
    "        newS = np.polyval(polyCoeffs, fitpts)\n",
    "        interpfun = interpolate.interp1d(fitpts, newS)\n",
    "        newSNormalLength = interpfun(intPts)\n",
    "        pNew[s, :] = newSNormalLength\n",
    "    train_inputs[i] = pNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_test = len(test_inputs)\n",
    "\n",
    "for i in range(num_test):\n",
    "    p = test_inputs[i]\n",
    "    pNew = np.zeros((12, virtualLength))\n",
    "    l = p.shape[1]\n",
    "    fitpts = np.asarray(range(l))\n",
    "    intPts = np.linspace(0, l - 1, num = 4)\n",
    "    for s in range(12):\n",
    "        polyCoeffs = np.polyfit(fitpts, p[s, :], polyOrder)\n",
    "        newS = np.polyval(polyCoeffs, fitpts)\n",
    "        interpfun = interpolate.interp1d(fitpts, newS)\n",
    "        newSNormalLength = interpfun(intPts)\n",
    "        pNew[s, :] = newSNormalLength\n",
    "    test_inputs[i] = pNew    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_conceptors(all_train_states,\n",
    "                      apN):\n",
    "    CPoss = []\n",
    "    RPoss = []\n",
    "    ROthers = []\n",
    "    CNegs = []\n",
    "    statesAllClasses = np.hstack(all_train_states)\n",
    "    Rall = statesAllClasses.dot(statesAllClasses.T)\n",
    "    I = np.eye(Rall.shape[0])\n",
    "    for i in range(len(all_train_states)):\n",
    "        R = all_train_states[i].dot(all_train_states[i].T)\n",
    "        Rnorm = R / all_train_states[i].shape[1]\n",
    "        RPoss.append(Rnorm)\n",
    "        ROther = Rall - R\n",
    "        ROthersNorm = ROther / (statesAllClasses.shape[1] - all_train_states[i].shape[1])\n",
    "        ROthers.append(ROthersNorm)\n",
    "        CPossi = []\n",
    "        CNegsi = []\n",
    "        for api in range(apN):\n",
    "            C = Rnorm.dot(np.linalg.inv(Rnorm + (2 ** float(api)) ** (-2) * I))\n",
    "            CPossi.append(C)\n",
    "            COther = ROthersNorm.dot(np.linalg.inv(ROthersNorm + (2 ** float(api)) ** (-2) * I))\n",
    "            CNegsi.append(I - COther)\n",
    "        CPoss.append(CPossi)\n",
    "        CNegs.append(CNegsi)\n",
    "    return CPoss, RPoss, ROthers, CNegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_aperture(C_pos_list,\n",
    "                     apN):\n",
    "    classnum = len(C_pos_list)\n",
    "    best_aps_pos = []\n",
    "    apsExploreExponents = np.asarray(range(apN))\n",
    "    intPts = np.arange(apsExploreExponents[0], apsExploreExponents[-1] + 0.01, 0.01)\n",
    "    for i in range(classnum):\n",
    "        norm_pos = np.zeros(apN)\n",
    "        for api in range(apN):\n",
    "            norm_pos[api] = np.linalg.norm(C_pos_list[i][api], 'fro') ** 2      \n",
    "        f_pos = interpolate.interp1d(np.arange(apN), norm_pos, kind=\"cubic\")\n",
    "        norm_pos_inter = f_pos(intPts)\n",
    "        norm_pos_inter_grad = (norm_pos_inter[1:] - norm_pos_inter[0:-1]) / 0.01\n",
    "        max_ind_pos = np.argmax(np.abs(norm_pos_inter_grad), axis = 0)    \n",
    "        best_aps_pos.append(2 ** intPts[max_ind_pos])  \n",
    "    return best_aps_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_best_conceptor(R_list,\n",
    "                           best_apt):\n",
    "    classnum = len(R_list)\n",
    "    C_best_list = []\n",
    "    I = np.eye(R_list[0].shape[0])\n",
    "    for i in range(classnum):\n",
    "        C_best = R_list[i].dot(np.linalg.inv(R_list[i] + best_apt ** (-2) * I))\n",
    "        C_best_list.append(C_best)      \n",
    "    return C_best_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "M = N + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassifications using positive evidence: 8\n",
      "misclassifications using negtive evidence: 6\n",
      "misclassifications using combined evidence: 4\n"
     ]
    }
   ],
   "source": [
    "    RNN = reservoir.Reservoir(12, 10, sr = 1.2, in_scale = 0.2, bias_scale = 1)\n",
    "\n",
    "    all_train_data = np.dstack(train_inputs)\n",
    "    all_train_data = all_train_data.swapaxes(1, 2)\n",
    "    hid_states, raw_hid_states= RNN.augment(all_train_data, 1)\n",
    "\n",
    "    all_test_data = np.dstack(test_inputs)\n",
    "    all_test_data = all_test_data.swapaxes(1, 2)\n",
    "    hid_states_test, raw_hid_states_test = RNN.augment(all_test_data, 1)\n",
    "\n",
    "    all_states_train = np.vstack((raw_hid_states, all_train_data))\n",
    "\n",
    "    all_states_test = np.vstack((raw_hid_states_test, all_test_data))\n",
    "\n",
    "    all_states_train = all_states_train.swapaxes(1, 2).reshape((-1, num_train), order = 'F')\n",
    "\n",
    "    all_states_test = all_states_test.swapaxes(1, 2).reshape((-1, num_test), order = 'F')\n",
    "\n",
    "    states_list_train = np.hsplit(all_states_train, 9)\n",
    "    \n",
    "    japvow_rec = recog.Recognizer()\n",
    "\n",
    "    japvow_rec.compute_conceptors(states_list_train)\n",
    "\n",
    "    japvow_rec.aperture_adjust()\n",
    "    \n",
    "    japvow_rec.compute_best_conceptors()\n",
    "\n",
    "    results_pos, evidence_pos = japvow_rec.evidence(all_states_test, japvow_rec.Cs_best_pos)\n",
    "\n",
    "    results_neg, evidence_neg = japvow_rec.evidence(all_states_test, japvow_rec.Cs_best_neg)\n",
    "    \n",
    "    results_comb, combEv = japvow_rec.combine_evidence(evidence_pos, evidence_neg)\n",
    "    \n",
    "    correct_results = []\n",
    "    block_lengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "    for i in range(9):\n",
    "        num = block_lengthes[i]\n",
    "        resulti = np.zeros(num).astype(int) + i\n",
    "        correct_results.append(resulti)\n",
    "    correct_results = np.hstack(correct_results)\n",
    "\n",
    "    misclasnum_pos = np.sum(correct_results != results_pos)\n",
    "\n",
    "    misclasnum_neg = np.sum(correct_results != results_neg)\n",
    "\n",
    "    misclasnum_comb = np.sum(correct_results != results_comb)\n",
    "\n",
    "    print('misclassifications using positive evidence:', misclasnum_pos)\n",
    "\n",
    "    print('misclassifications using negtive evidence:', misclasnum_neg)\n",
    "\n",
    "    print('misclassifications using combined evidence:', misclasnum_comb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TestJapVow():\n",
    "    RNN = reservoir.Reservoir(12, 10, sr = 1.2, in_scale = 0.2, bias_scale = 1)\n",
    "\n",
    "    all_train_data = np.dstack(train_inputs)\n",
    "    all_train_data = all_train_data.swapaxes(1, 2)\n",
    "    hid_states, raw_hid_states= RNN.augment(all_train_data, 1)\n",
    "\n",
    "    all_test_data = np.dstack(test_inputs)\n",
    "    all_test_data = all_test_data.swapaxes(1, 2)\n",
    "    hid_states_test, raw_hid_states_test = RNN.augment(all_test_data, 1)\n",
    "\n",
    "    all_states_train = np.vstack((raw_hid_states, all_train_data))\n",
    "\n",
    "    all_states_test = np.vstack((raw_hid_states_test, all_test_data))\n",
    "\n",
    "    all_states_train = all_states_train.swapaxes(1, 2).reshape((-1, num_train), order = 'F')\n",
    "\n",
    "    all_states_test = all_states_test.swapaxes(1, 2).reshape((-1, num_test), order = 'F')\n",
    "\n",
    "    states_list_train = np.hsplit(all_states_train, 9)\n",
    "    \n",
    "    japvow_rec = recog.Recognizer()\n",
    "\n",
    "    japvow_rec.compute_conceptors(states_list_train)\n",
    "\n",
    "    japvow_rec.aperture_adjust()\n",
    "    \n",
    "    japvow_rec.compute_best_conceptors()\n",
    "\n",
    "    results_pos, evidence_pos = japvow_rec.evidence(all_states_test, japvow_rec.Cs_best_pos)\n",
    "\n",
    "    results_neg, evidence_neg = japvow_rec.evidence(all_states_test, japvow_rec.Cs_best_neg)\n",
    "    \n",
    "    results_comb, combEv = japvow_rec.combine_evidence(evidence_pos, evidence_neg)\n",
    "    \n",
    "    correct_results = []\n",
    "    block_lengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "    for i in range(9):\n",
    "        num = block_lengthes[i]\n",
    "        resulti = np.zeros(num).astype(int) + i\n",
    "        correct_results.append(resulti)\n",
    "    correct_results = np.hstack(correct_results)\n",
    "\n",
    "    misclasnum_pos = np.sum(correct_results != results_pos)\n",
    "\n",
    "    misclasnum_neg = np.sum(correct_results != results_neg)\n",
    "\n",
    "    misclasnum_comb = np.sum(correct_results != results_comb)\n",
    "    \n",
    "   # print('misclassifications using positive evidence:', misclasnum_pos)\n",
    "\n",
    "   # print('misclassifications using negtive evidence:', misclasnum_neg)\n",
    "\n",
    "   # print('misclassifications using combined evidence:', misclasnum_comb)\n",
    "    \n",
    "    return misclasnum_pos, misclasnum_neg, misclasnum_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.4 5.9 4.92\n"
     ]
    }
   ],
   "source": [
    "totalmis_pos = 0\n",
    "totalmis_neg = 0\n",
    "totalmis_comb = 0\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    miscla_pos, miscla_neg, miscla_comb = TestJapVow()\n",
    "    totalmis_pos += miscla_pos\n",
    "    totalmis_neg += miscla_neg\n",
    "    totalmis_comb += miscla_comb\n",
    "\n",
    "print(totalmis_pos / 50, totalmis_neg / 50, totalmis_comb / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassifications using combined evidence: 5\n"
     ]
    }
   ],
   "source": [
    "    RNN = reservoir.Reservoir(12, 10, sr = 1.2, in_scale = 0.2, bias_scale = 1)\n",
    "\n",
    "    all_train_data = np.dstack(train_inputs)\n",
    "    all_train_data = all_train_data.swapaxes(1, 2)\n",
    "    hid_states, raw_hid_states= RNN.augment(all_train_data, 1)\n",
    "\n",
    "    all_test_data = np.dstack(test_inputs)\n",
    "    all_test_data = all_test_data.swapaxes(1, 2)\n",
    "    hid_states_test, raw_hid_states_test = RNN.augment(all_test_data, 1)\n",
    "\n",
    "    all_states_train = np.vstack((raw_hid_states, all_train_data))\n",
    "\n",
    "    all_states_test = np.vstack((raw_hid_states_test, all_test_data))\n",
    "\n",
    "    all_states_train = all_states_train.swapaxes(1, 2).reshape((-1, num_train), order = 'F')\n",
    "\n",
    "    all_states_test = all_states_test.swapaxes(1, 2).reshape((-1, num_test), order = 'F')\n",
    "\n",
    "    states_list_train = np.hsplit(all_states_train, 9)\n",
    "    \n",
    "    japvow_rec = recog.Recognizer()\n",
    "\n",
    "    japvow_rec.train(states_list_train)\n",
    "    \n",
    "    results = japvow_rec.predict(all_states_test)\n",
    "\n",
    "    correct_results = []\n",
    "    block_lengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "    for i in range(9):\n",
    "        num = block_lengthes[i]\n",
    "        resulti = np.zeros(num).astype(int) + i\n",
    "        correct_results.append(resulti)\n",
    "    correct_results = np.hstack(correct_results)\n",
    "\n",
    "    misclasnum = np.sum(correct_results != results)\n",
    "\n",
    "    print('misclassifications using combined evidence:', misclasnum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
