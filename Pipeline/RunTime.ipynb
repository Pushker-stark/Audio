{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the audio processing tools are wrapped in the Python Module called AudioPipe\n",
    "import AudioPipe.speaker.recognition as SR # Speaker Recognition Module\n",
    "import AudioPipe.fingerprint.panako as FP # Accoustic Fingerprinting Module\n",
    "from AudioPipe.speaker.silence import remove_silence # tool for remove the silence in the audio, not needed\n",
    "import numpy as np\n",
    "from AudioPipe.features import mfcc # Feature Extraction Module, part of the shared preprocessing\n",
    "import scipy.io.wavfile as wav \n",
    "from AudioPipe.speaker.rec import dia2spk, getspk # Speaker Recognition using diarization results\n",
    "from AudioPipe.utils.utils import video2audio # Format converting module, part of the shared preprocessing\n",
    "import commands, os\n",
    "from AudioPipe.diarization.diarization import Diarization # Speaker Diarization Moudule\n",
    "import AudioPipe.data.manage as DM # Data Management Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Select the video file to be processed\n",
    "Video_node = DM.Node(\"Data/Video/\",\".mp4\")\n",
    "name = \"2015-08-07_0050_US_FOX-News_US_Presidential_Politics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Select the file for the meta infomation\n",
    "Meta_node = DM.Node(\"Data/RedHen/\",\".seg\")\n",
    "meta = Meta_node.Pick(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Convert the video to audio\n",
    "Audio_node = DM.Node(\"Data/Audio/\", \".wav\")\n",
    "audio = Video_node.Flow(video2audio, name, Audio_node, [Audio_node.ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dia = \"Data/Diarization/2015-08-07_0050_US_FOX-News_US_Presidential_Politics.rttm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below you can find an example on training a fresh model\n",
    "# However, please make sure that the sample rate of your training data is the same with your testing data\n",
    "model_gender_dir = \"Data/Model/Gender/\"\n",
    "model_gender_nm = 'gender.model'\n",
    "model_gender = model_gender_dir+model_gender_nm\n",
    "if not os.path.isfile(model_gender):\n",
    "    Gender = SR.GMMRec() # Create a new recognizer\n",
    "    female_fn = model_gender_dir+'female.wav' # choose the training file for female\n",
    "    male_fn = model_gender_dir+'male.wav' # choose the training file for male\n",
    "    Gender.enroll_file('Female', female_fn) # enroll the female audio \n",
    "    Gender.enroll_file('Male', male_fn) # enroll the male audio \n",
    "    Gender.train() # train the GMMs after you enroll all the training data \n",
    "    Gender.dump(model_gender) # save the trained model into a file named \"gender.model\" for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Gender Identification based on Speaker Diarization\n",
    "Gen_node = DM.Node(\"Data/Gender/\",\".gen\")\n",
    "gen = Audio_node.Flow(dia2spk, name, Gen_node, [model_gender, dia, meta, Gen_node.ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Gender Identification without Speaker Diarization\n",
    "Genr_node = DM.Node(\"Data/Gender/\",\".genr\")\n",
    "gen = Audio_node.Flow(getspk, name, Genr_node, [model_gender, meta, Genr_node.ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can train a fresh model as follows:\n",
    "model_speaker_dir = \"Data/Model/Speaker/\" # The training data should already be here!! \n",
    "model_speaker_nm = 'speaker.model'\n",
    "model_speaker = model_speaker_dir+model_speaker_nm\n",
    "if not os.path.isfile(model_speaker):\n",
    "    Speaker = SR.GMMRec() # Create a new recognizer\n",
    "    other_fn = model_speaker_dir+'Imposter.wav' # choose the training file for female\n",
    "    trump_fn = model_speaker_dir+'Trump.wav' # choose the training file for male\n",
    "    Speaker.enroll_file('Other', other_fn) # enroll the female audio \n",
    "    Speaker.enroll_file('Trump', trump_fn) # enroll the male audio \n",
    "    # You can add more speakers here following the syntax above\n",
    "    Speaker.train() # train the GMMs after you enroll all the training data \n",
    "    Speaker.dump(model_speaker) # save the trained model into a file named \"gender.model\" for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n",
      "---running time: 55.6282031536 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Speaker Recognition based on Speaker Diarization\n",
    "start_time = time.time()\n",
    "Spk_node = DM.Node(\"Data/Speaker/\",\".spk\")\n",
    "spk = Audio_node.Flow(dia2spk, name, Spk_node, [model_speaker, dia, meta, Spk_node.ext])\n",
    "print(\"---running time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n",
      "---running time: 51.3849680424 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Speaker Recognition without Speaker Diarization\n",
    "start_time = time.time()\n",
    "Spkr_node = DM.Node(\"Data/Speaker/\",\".spkr\")\n",
    "spkr = Audio_node.Flow(getspk, name, Spkr_node, [model_speaker, meta, Spkr_node.ext])\n",
    "print(\"---running time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
