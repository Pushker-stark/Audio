{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the audio processing tools are wrapped in the Python Module called AudioPipe\n",
    "import AudioPipe.speaker.recognition as SR # Speaker Recognition Module\n",
    "import AudioPipe.fingerprint.panako as FP # Accoustic Fingerprinting Module\n",
    "from AudioPipe.speaker.silence import remove_silence # tool for remove the silence in the audio, not needed\n",
    "import numpy as np\n",
    "from AudioPipe.features import mfcc # Feature Extraction Module, part of the shared preprocessing\n",
    "import scipy.io.wavfile as wav \n",
    "from AudioPipe.speaker.rec import dia2spk, getspk # Speaker Recognition using diarization results\n",
    "from AudioPipe.utils.utils import video2audio # Format converting module, part of the shared preprocessing\n",
    "import commands, os\n",
    "from AudioPipe.diarization.diarization import Diarization # Speaker Diarization Moudule\n",
    "import AudioPipe.data.manage as DM # Data Management Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Select the video file to be processed\n",
    "Video_node = DM.Node(\"Data/Video/\",\".mp4\")\n",
    "name = \"2015-08-07_0050_US_FOX-News_US_Presidential_Politics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Select the file for the meta infomation\n",
    "Meta_node = DM.Node(\"Data/RedHen/\",\".seg\")\n",
    "meta = Meta_node.Pick(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Convert the video to audio\n",
    "Audio_node = DM.Node(\"Data/Audio/\", \".wav\")\n",
    "audio = Video_node.Flow(video2audio, name, Audio_node, [Audio_node.ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dia = \"Data/Diarization/2015-08-07_0050_US_FOX-News_US_Presidential_Politics.rttm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below you can find an example on training a fresh model\n",
    "# However, please make sure that the sample rate of your training data is the same with your testing data\n",
    "model_gender_dir = \"Data/Model/Gender/\"\n",
    "model_gender_nm = 'gender.model'\n",
    "model_gender = model_gender_dir+model_gender_nm\n",
    "if not os.path.isfile(model_gender):\n",
    "    Gender = SR.GMMRec() # Create a new recognizer\n",
    "    female_fn = model_gender_dir+'female.wav' # choose the training file for female\n",
    "    male_fn = model_gender_dir+'male.wav' # choose the training file for male\n",
    "    Gender.enroll_file('Female', female_fn) # enroll the female audio \n",
    "    Gender.enroll_file('Male', male_fn) # enroll the male audio \n",
    "    Gender.train() # train the GMMs after you enroll all the training data \n",
    "    Gender.dump(model_gender) # save the trained model into a file named \"gender.model\" for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Gender Identification based on Speaker Diarization\n",
    "Gen_node = DM.Node(\"Data/Gender/\",\".gen\")\n",
    "gen = Audio_node.Flow(dia2spk, name, Gen_node, [model_gender, dia, meta, Gen_node.ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "# Gender Identification without Speaker Diarization\n",
    "Genr_node = DM.Node(\"Data/Gender/\",\".genr\")\n",
    "gen = Audio_node.Flow(getspk, name, Genr_node, [model_gender, meta, Genr_node.ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can train a fresh model as follows:\n",
    "model_speaker_dir = \"Data/Model/Speaker/\" # The training data should already be here!! \n",
    "model_speaker_nm = 'speaker.model'\n",
    "model_speaker = model_speaker_dir+model_speaker_nm\n",
    "if not os.path.isfile(model_speaker):\n",
    "    Speaker = SR.GMMRec() # Create a new recognizer\n",
    "    other_fn = model_speaker_dir+'Imposter.wav' # choose the training file for female\n",
    "    trump_fn = model_speaker_dir+'Trump.wav' # choose the training file for male\n",
    "    Speaker.enroll_file('Other', other_fn) # enroll the female audio \n",
    "    Speaker.enroll_file('Trump', trump_fn) # enroll the male audio \n",
    "    # You can add more speakers here following the syntax above\n",
    "    Speaker.train() # train the GMMs after you enroll all the training data \n",
    "    Speaker.dump(model_speaker) # save the trained model into a file named \"gender.model\" for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n",
      "---running time: 75.5289838314 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Speaker Recognition based on Speaker Diarization\n",
    "start_time = time.time()\n",
    "Spk_node = DM.Node(\"Data/Speaker/\",\".spk\")\n",
    "spk = Audio_node.Flow(dia2spk, name, Spk_node, [model_speaker, dia, meta, Spk_node.ext])\n",
    "print(\"---running time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Speaker Recognition without Speaker Diarization\n",
    "start_time = time.time()\n",
    "Spkr_node = DM.Node(\"Data/Speaker/\",\".spkr\")\n",
    "spkr = Audio_node.Flow(getspk, name, Spkr_node, [model_speaker, meta, Spkr_node.ext])\n",
    "print(\"---running time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uid2time(uid, prefix='', more_entropy=0):\n",
    "    uid = uid[len(prefix):]\n",
    "    if more_entropy:\n",
    "        uid = uid[:-more_entropy]\n",
    "    i = int(uid[:12],16)\n",
    "    f = float(int(uid[12:],16))/1000000\n",
    "    return i+f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string, time, math, random\n",
    "def uniqid(m, prefix='', more_entropy=0):\n",
    "    uniqid = '%8x%05x' %(math.floor(m),(m-math.floor(m))*1000000)\n",
    "    if more_entropy:\n",
    "        valid_chars = list(set(string.hexdigits.lower()))\n",
    "        entropy_string = ''\n",
    "        for i in range(0,more_entropy,1):\n",
    "            entropy_string += random.choice(valid_chars)\n",
    "        uniqid = uniqid + entropy_string\n",
    "    uniqid = prefix + uniqid\n",
    "    return uniqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20150807005009.5"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = '20150807005009.500'\n",
    "float(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1253b9b187517a120d21d2c04d9'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = uniqid(float(timestamp), more_entropy=10)\n",
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20150807005009.500'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp1 = uid2time(uid,more_entropy=10)\n",
    "'%.3f' % timestamp1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
